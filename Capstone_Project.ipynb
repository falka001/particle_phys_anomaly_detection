{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba74443-2f5c-4fa0-a759-5cbe507b7ba5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7062a4-9b7e-438f-9f82-d74bb9f96258",
   "metadata": {
    "id": "51f0c46a-fcee-4a02-b340-96c5719702d2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy as cp\n",
    "\n",
    "import energyflow as ef\n",
    "from energyflow.archs import CNN\n",
    "from energyflow.datasets import qg_jets\n",
    "from energyflow.utils import data_split, pixelate, standardize, to_categorical, zero_center\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b056a99-a344-4542-b013-639960163718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used for ODU's HPC\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e57a72-f205-4826-917b-862492d90c98",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66710e-4bfe-4d57-aa65-6e33a7a00624",
   "metadata": {
    "id": "15eff2d4-667a-4bd1-b41a-1fd091acdf71"
   },
   "outputs": [],
   "source": [
    "# load data \n",
    "X, y = qg_jets.load(num_data=100000)      # remove PID\n",
    "\n",
    "X = X[:,:,:3]\n",
    "\n",
    "# convert labels to categorical\n",
    "Y = to_categorical(y, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5edb8d-6fca-433f-a9b4-0856b321ef34",
   "metadata": {
    "id": "3ce47d1c-3b89-4ad9-a5ad-67021aa78b81"
   },
   "outputs": [],
   "source": [
    "# image parameters\n",
    "R = 0.4\n",
    "img_width = 2*R\n",
    "npix = 64\n",
    "nb_chan = 1               # just one channel\n",
    "norm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7a983-531f-4bb7-ab9c-1c3973da4c8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30995fe-963b-459d-8500-da0237081716",
   "metadata": {
    "id": "9d0f8843-af19-4f45-be0d-997d0cf1294d"
   },
   "outputs": [],
   "source": [
    "# preprocess by centering jets and normalizing pts\n",
    "for x in X:\n",
    "    mask = x[:,0] > 0                                                                # Takes the particles that have transverse momentum\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)                    # Takes the average of the rapidity and phi\n",
    "    x[mask,1:3] -= yphi_avg                                                          # subtracting each rapidity and phi by the average\n",
    "    x[mask,0] /= x[:,0].sum()                                                        # normalizing the transverse momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f2dcf-8050-4283-95c3-cef20458abbb",
   "metadata": {
    "id": "2a544656-c967-42da-aae6-d87e26429752"
   },
   "outputs": [],
   "source": [
    "# make jet images\n",
    "images2 = np.asarray([pixelate(x, npix=npix, img_width=img_width, nb_chan=nb_chan, \n",
    "                                 charged_counts_only=False, norm=norm) for x in X])\n",
    "# images = jet, phi, rapidty, pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e80984-6230-40f6-a36b-8ce86a23831f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EeSs-3FUdXXB",
    "outputId": "81f3506c-713f-4147-cb93-2a37392a1cca"
   },
   "outputs": [],
   "source": [
    "images2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b800f7-bb47-4c41-b891-82fbe476e290",
   "metadata": {
    "id": "37c18ddb-c7fe-4606-87b6-abab43c69c9c"
   },
   "outputs": [],
   "source": [
    "(X_train2, X_test2, Y_train2, Y_test2) = train_test_split(images2,Y, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853fb59-ca6f-415f-ba67-053b307123ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTtsQJNMQiAR",
    "outputId": "84e35d9f-fd16-48f4-bbd1-770efdca28c9"
   },
   "outputs": [],
   "source": [
    "X_train2.shape, X_test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac57622-fb8a-4cff-ab0a-22672b960e43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Jet Image Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19059b5f-7bda-4c91-8a0a-1571e9e580b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(X_test2[0,:,:], cmap = 'Blues')\n",
    "plt.xlabel(\"Phi\", fontsize = 15)\n",
    "plt.ylabel(\"Rapidity\", fontsize = 15)\n",
    "plt.colorbar()\n",
    "#plt.savefig(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1f2e3-0acb-44a2-b18d-81af193cd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "zval_org = X_test2.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5998e1-d229-4d69-b199-26da43c46ffa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Z-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152a7be-9802-4d3d-a0ec-40fd88fc5a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.hist(zval_org, bins = 30, color = 'b', histtype = 'step')\n",
    "plt.xlabel(\"Z-values\", fontsize = 12)\n",
    "plt.ylabel(\"Count (log base 10 scaling)\", fontsize = 12)\n",
    "plt.semilogy()\n",
    "#plt.savefig(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d463e-023a-4a07-af0f-df9869716cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bounds = [0]\n",
    "zval_log = np.log10(zval_org[zval_org != 0])\n",
    "plt.hist(zval_log, bins = 50, color = 'b', histtype = 'step')\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"Z-values\", fontsize = 12)\n",
    "plt.ylabel(\"Count (log base 10 scaling)\", fontsize = 12)\n",
    "#plt.savefig(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87108bb9-0e09-4473-be7b-30c2441aa4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.hist(zval_log, bins = 50, color = 'b', histtype = 'step')\n",
    "plt.xlabel(\"Z-values\", fontsize = 12)\n",
    "plt.ylabel(\"Count\", fontsize = 12)\n",
    "#plt.savefig(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11f543-7b23-48c9-b4a8-e7fdceb83325",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = np.concatenate([np.nonzero(x)[0] for x in X_test2])\n",
    "rapidity = np.concatenate([np.nonzero(x)[1] for x in X_test2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b0c222-fe75-477b-8030-573844ba4f31",
   "metadata": {},
   "source": [
    "## Phi-distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b7410c-ee8e-41b7-af92-391d671c66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.hist(phi, bins = 20, color = 'b', histtype = 'step', label = 'Phi')\n",
    "plt.hist(rapidity, bins = 20, color = 'r', histtype = 'step', label = 'Rapidity')\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"Phi and Rapidity\", fontsize = 12)\n",
    "plt.ylabel(\"Count (log base 10 scaling)\", fontsize = 12)\n",
    "plt.legend()\n",
    "#plt.savefig(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff4b52-e205-4e14-af49-aa2770f71d5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Image Transformation: imgs_trnsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e05f1-bc9f-4a21-8f40-2e3a3cfd8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_trnsf = cp.deepcopy(images2)\n",
    "imgs_trnsf[imgs_trnsf == 0] = 10\n",
    "imgs_trnsf = np.log10(imgs_trnsf)\n",
    "imgs_trnsf[imgs_trnsf == 1] = -8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878bf62-1bec-4e61-a7b9-8fc83a2a8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "zval_trnsf = imgs_trnsf.flatten()\n",
    "%matplotlib inline\n",
    "plt.hist(zval_trnsf, bins = 50, color = 'b', histtype = 'step')\n",
    "plt.semilogy()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da991be-0034-4833-bc3b-371401d52df8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Standard Autoencoder: SAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7521fc-7610-4e4f-affd-5805443c7d08",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cca9957-2305-41fc-a6d5-86485e07d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ###\n",
    "lr = ###\n",
    "activ = 'elu'\n",
    "rate = ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2707f9-a16c-4699-859e-3b084aa55e83",
   "metadata": {
    "id": "a2a36a6d-7f80-4213-9764-617273df4061",
    "tags": []
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e67a31-af91-4102-af9f-e69b6aa2b6eb",
   "metadata": {
    "id": "f277c0f1-997f-4216-a89e-a673b6e56fc1"
   },
   "outputs": [],
   "source": [
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(input_img[0])\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.AveragePooling2D(pool_size = (2,2), strides = (1,1), padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.AveragePooling2D(pool_size = (2,2), strides = (1,1), padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "encoded64 = layers.Dense(units = 256, activation = activ)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17faec-72a3-44c0-8b6a-eaef48942d14",
   "metadata": {
    "id": "6b4b808a-a8ed-4ced-9e3c-1a47170e1e3c",
    "tags": []
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4e409-7ca3-472d-bd58-c21d030b2c6a",
   "metadata": {
    "id": "c1a1ae21-7a4c-445f-995f-340bdb866313"
   },
   "outputs": [],
   "source": [
    "x = layers.Dense(units = 256, activation = activ)(encoded64)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Reshape(target_shape=(16,16, 1))(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(kernel, (3,3), strides = 2, padding = 'same', activation = activ)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(kernel, (3,3), strides = 2, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "decoded64 = layers.Conv2D(1, (3,3), activation = 'sigmoid', padding = 'same')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d92401-480e-4b75-a57f-2d0a2deed384",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe9465-1a5b-4574-9f23-f8435b5a9253",
   "metadata": {
    "id": "faadd66c-f693-42c5-b925-058b3ff54103"
   },
   "outputs": [],
   "source": [
    "autoencoder1 = keras.Model(input_img[0], decoded64)\n",
    "#autoencoder2 = keras.Model(input_img[1], decoded64)\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "autoencoder1.compile(optimizer = opt, loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1588101a-0efd-4e39-a867-9402cf1089cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 60)\n",
    "history1 = autoencoder1.fit(x = images2, y = images2, epochs = 100, batch_size = 32, shuffle = True,\n",
    "                                validation_split = 0.20, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f316221-2abd-4c6b-9a3e-6e0dfc652df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(loss, epochs, color, label):\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "    plt.plot(loss[0], color[0], label = label[0])\n",
    "    plt.plot(loss[1], color[1], label = label[1])\n",
    "    plt.legend()\n",
    "    plt.semilogy()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ac5f6-e58e-40b1-ada1-3266e2c8e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = [history1.history['loss'], history2.history['loss']]\n",
    "val_loss = [history1.history['val_loss'], history2.history['val_loss']]\n",
    "\n",
    "loss1 = [training_loss[0], val_loss[0]]\n",
    "loss2 = [training_loss[1], val_loss[1]]\n",
    "\n",
    "# Visualize loss history\n",
    "plt.figure(figsize=(15,10))\n",
    "colors = ['r--', 'b-']\n",
    "labels = ['training','validation']\n",
    "plotting(loss1, 100, colors, labels)\n",
    "colors = ['g--', 'k-']\n",
    "labels = ['training_trnsf','validation_trnsf']\n",
    "plotting(loss2, 100, colors, labels)\n",
    "#plt.savefig(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1aa43-d54f-401e-ba5f-44faa430c90b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36414c44-664d-4341-a690-d96315d62594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(filters, rate, lr, activ_choice):\n",
    "    \n",
    "    input_img = keras.Input(shape = (64,64,1))\n",
    "        # Encoding\n",
    "    x = layers.Conv2D(filters, (3,3), activation = activ_choice, padding = 'same')(input_img)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    x = layers.Conv2D(filters, (3,3), activation = activ_choice, padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    x = layers.AveragePooling2D(pool_size = (2,2), strides = (1,1), padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    x = layers.Conv2D(filters, (3,3), activation = activ_choice, padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    x = layers.Conv2D(filters, (3,3), activation = activ_choice, padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    x = layers.AveragePooling2D(pool_size = (2,2), strides = (1,1), padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    encoded = layers.Dense(units = 256, activation = activ_choice)(x)\n",
    "    \n",
    "        # Decoding\n",
    "    x = layers.Dense(units = 256, activation = activ_choice)(encoded)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    x = layers.Reshape(target_shape=(16,16, 1))(x)\n",
    "    x = layers.Conv2DTranspose(filters, (3,3), strides = 2, padding = 'same', activation = activ_choice)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    x = layers.Conv2D(filters, (3,3), activation = activ_choice, padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    x = layers.Conv2D(filters, (3,3), activation = activ_choice, padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    x = layers.Conv2DTranspose(filters, (3,3), strides = 2, padding = 'same', activation = activ_choice)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    x = layers.Conv2D(filters, (3,3), activation = activ_choice, padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(rate)(x)\n",
    "    decoded = layers.Conv2D(1, (3,3), activation = 'sigmoid', padding = 'same')(x)\n",
    "    \n",
    "    model = keras.Model(input_img, decoded)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa68954-d330-4199-ade8-99979b2d4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AE_hps(hp):\n",
    "    filters = hp.Int(\"filters\", min_value = 2, max_value = 16, step = 4)\n",
    "    rate = hp.Float(\"rate\", min_value = 0.0, max_value = 0.30, step = 0.05)\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
    "    choice = 'elu'\n",
    "    \n",
    "    hpmodel = model(filters = filters, rate = rate, lr = learning_rate, activ_choice = choice)\n",
    "    return hpmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616fe34-7b94-401f-a328-17240299d416",
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_hps(kt.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85836a7-9f3e-496d-8e1a-14ba1423511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(hypermodel = AE_hps, objective = 'val_loss', max_trials = 100, \n",
    "                                num_initial_points=None, alpha=0.0001, \n",
    "                                beta=4, max_consecutive_failed_trials=2,\n",
    "                               directory=\"bayesianopt\", project_name=\"autoencoder\")\n",
    "    # beta - Exploration and exploitation. The larger it is, the more explorative it is.\n",
    "    # alpha - Expected amount of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2cb5db-38a5-409d-aee3-a850f6dfc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "tuner.search(x = images2, y = images2, epochs = 100, batch_size = 32, shuffle = True,\n",
    "                              validation_split = 0.20, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a9703-5c52-4455-85a3-1e70ef0bf145",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Variational Autoencoder: VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ee61d-a64f-45f5-b4ac-7cc959029434",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b281ee-9697-4945-8534-cc83d447f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 16\n",
    "lr = 0.00001\n",
    "activ = 'elu'\n",
    "rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db013087-7b68-4764-8162-9fa56661791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        sample = z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b61e2-8e37-4f75-8500-0bd2c9e0157f",
   "metadata": {
    "id": "f277c0f1-997f-4216-a89e-a673b6e56fc1"
   },
   "outputs": [],
   "source": [
    "encoder_input = keras.Input(shape = (images2.shape[1],images2.shape[1],1))\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(encoder_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.AveragePooling2D(pool_size = (2,2), strides = (1,1), padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.AveragePooling2D(pool_size = (2,2), strides = (1,1), padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(units = 256, activation = activ)(x)\n",
    "encoded = layers.Dense(units = 64, activation = activ)(x)\n",
    "z_mean = layers.Dense(64, name = 'mean')(encoded)\n",
    "z_log_var = layers.Dense(64, name = 'log_var')(encoded)\n",
    "z = sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_input, [z_mean, z_log_var, z], name = 'encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e2a7c-1e64-4cea-9e03-ad0075fa9626",
   "metadata": {
    "id": "c1a1ae21-7a4c-445f-995f-340bdb866313"
   },
   "outputs": [],
   "source": [
    "decoder_input = keras.Input(shape = (64,))\n",
    "\n",
    "x = layers.Dense(units = 64, activation = activ)(decoder_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Dense(units = 256, activation = activ)(decoder_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Reshape(target_shape=(16,16, 1))(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(kernel, (3,3), strides = 2, padding = 'same', activation = activ)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(kernel, (3,3), strides = 2, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "x = layers.Conv2D(kernel, (3,3), activation = activ, padding = 'same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(rate)(x)\n",
    "\n",
    "decoded = layers.Conv2D(1, (3,3), activation = 'sigmoid', padding = 'same')(x)\n",
    "decoder = keras.Model(decoder_input, decoded, name = 'decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a8d41-89ac-4eb0-bd75-6599e931c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mean_squared_error(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81594829-1222-4db3-aa0b-73bb1385f1ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db904c-3a6d-4b26-83d0-3600bda32738",
   "metadata": {
    "id": "faadd66c-f693-42c5-b925-058b3ff54103"
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer = opt)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'kl_loss', patience = 20)\n",
    "history = vae.fit(x = X_train2, epochs = 100, batch_size = 32, shuffle = True, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9c9da-017b-42e2-943e-85d49b0a4c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "training_loss = history.history['kl_loss']\n",
    "plt.figure(figsize=(10,5))\n",
    "colors = ['r--']\n",
    "labels = ['training']\n",
    "plt.plot(training_loss, colors[0], label = labels[0])\n",
    "plt.legend()\n",
    "plt.semilogy()\n",
    "plt.xlabel('Epoch', fontsize = 12)\n",
    "plt.ylabel('KL_Loss', fontsize = 12)\n",
    "#plt.savefig(\"VAE_klloss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5139e66a-bf97-458a-8e95-7dcc34b819ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbf392-0a7c-4aee-81b2-294013f82ec9",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40c1b87d-2685-4fa9-9972-c85da486cf27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58faa6a2-ce6b-4252-b726-71d4c9674b79",
    "outputId": "8dab2400-9cef-4a8b-fb78-11a4d1f7210c"
   },
   "outputs": [],
   "source": [
    "m, v, z = encoder.predict(X_test2)\n",
    "decoded_imgs = decoder.predict(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6190754-993a-48a7-a8a8-fe9fdbce5c51",
   "metadata": {},
   "source": [
    "## SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78636f-8eaa-4973-9b06-4d97b78bceef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58faa6a2-ce6b-4252-b726-71d4c9674b79",
    "outputId": "8dab2400-9cef-4a8b-fb78-11a4d1f7210c"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a397cb-e5fd-4bf5-bb9c-68ddb49b6000",
   "metadata": {},
   "source": [
    "## Plots & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b9fea-12a7-4129-b0d2-9a2cc5c25dc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926
    },
    "id": "e34cc9b1-9bc4-4ef7-8b1a-5b103555b89b",
    "outputId": "c341a27d-9fd5-48fb-8ffc-35d8e3267387"
   },
   "outputs": [],
   "source": [
    "def plotting(tested, predicted, epochs):\n",
    "    %matplotlib inline\n",
    "    n = 4\n",
    "    plt.figure(figsize=(30,20))\n",
    "    for i in range(1,n+1):\n",
    "        # Original\n",
    "        ax = plt.subplot(2, n, i)\n",
    "        plt.imshow(tested[i,:,:,0], cmap = 'Blues')\n",
    "        plt.colorbar()\n",
    "\n",
    "        # Reconstructed\n",
    "        ax = plt.subplot(2, n, i+n)\n",
    "        plt.imshow(predicted[i,:,:,0], cmap = 'Blues')\n",
    "        plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1226ce0-5b76-4de5-9fa9-fdba3b55bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"              100 epochs: Trained on original\")\n",
    "plotting(X_test2, decoded_imgs[0], num_epoch)\n",
    "print(\"              100 epochs: Trained on transformed\")\n",
    "plotting(X_test2, decoded_imgs[1], num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726139a-ccf0-45a5-a1a3-b5d41dc77880",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uEA1DKxgnk1",
    "outputId": "3c438db4-ae9a-45f8-f902-e7973b838763"
   },
   "outputs": [],
   "source": [
    "print(np.count_nonzero(X_test2), np.count_nonzero(X_test2)/(X_test2.shape[0]*X_test2.shape[1]*X_test2.shape[2])*100)\n",
    "print(np.count_nonzero(decoded_imgs[.]),  np.count_nonzero(decoded_imgs[.])/(decoded_imgs[.].shape[0]*decoded_imgs[.].shape[1]*decoded_imgs[.].shape[2])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b71a22-eb41-46cc-8f58-edd4f005e33d",
   "metadata": {
    "id": "b1c26f8e-fe55-4115-b83c-0829bf235855"
   },
   "outputs": [],
   "source": [
    "zval_org = X_test2.flatten()\n",
    "zval_pred = [decoded_imgs[0].flatten(), decoded_imgs[1].flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b9038-ff01-41a1-84ca-49418a6f0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(zvalues):\n",
    "    median = np.median(zvalues)\n",
    "    upper_quartile = np.percentile(zvalues, 75)\n",
    "    lower_quartile = np.percentile(zvalues, 25)\n",
    "\n",
    "    iqr = upper_quartile - lower_quartile\n",
    "    upper_whisker = zvalues[zvalues <= upper_quartile+1.5*iqr].max()\n",
    "    upper_whisker2 = zvalues[zvalues <= upper_quartile+3*iqr].max()\n",
    "    lower_whisker = zvalues[zvalues >= lower_quartile-1.5*iqr].min()\n",
    "    lower_whisker2 = zvalues[zvalues >= lower_quartile-3*iqr].min()\n",
    "    print(lower_whisker2, lower_whisker, lower_quartile, median, upper_quartile, upper_whisker, upper_whisker2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b1aa6-bc83-4cda-8d28-d1a81162e1e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvbiGaDoaCct",
    "outputId": "1b96892d-a314-43a1-910c-a43988c1bb7e"
   },
   "outputs": [],
   "source": [
    "for i in range(len(zval_pred)):\n",
    "    zval = zval_pred[i]\n",
    "    statistics(zval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109e080-469d-4972-baec-78c4366440e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-H3y7WdnjsyC",
    "outputId": "b7e93254-9d42-4417-ed65-ceef4768dfa5"
   },
   "outputs": [],
   "source": [
    "zval = zval_pred[#]\n",
    "bound = ###\n",
    "print(zval[zval < bound].shape[0]/zval.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38bc5ef-24df-4b2d-8ea1-052f7dadbc73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBEHJPTqVAS7",
    "outputId": "e229e11f-0259-40c0-a196-30050fbfddd0"
   },
   "outputs": [],
   "source": [
    "for i in range(len(zval_pred)):\n",
    "    print(mean_squared_error(zval_org, zval_pred[i]), math.sqrt(mean_squared_error(zval_org, zval_pred[i])))\n",
    "    print(mean_squared_log_error(zval_org, zval_pred[i]), math.sqrt(mean_squared_log_error(zval_org, zval_pred[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613c959-fd80-4c50-a412-de2593abd05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "colors = ['b', 'r', 'g']\n",
    "\n",
    "print(\"64 X 64 IMAGES, 100 EPOCHS: blue are original z's\")\n",
    "print()\n",
    "\n",
    "zvalp1 = zval_pred[#]\n",
    "\n",
    "zvalo_log = np.log10(zval_org[zval_org != 0])\n",
    "zvalp_log = [np.log10(zvalp1[zvalp1 != 0]),np.log10(zvalp2[zvalp2 != 0])]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(zvalo_log, bins = 50, color = colors[0], histtype = 'step', label = 'original')\n",
    "plt.hist(zvalp_log[.], bins = 50, color = colors[1], histtype = 'step', label = 'predicted_org')\n",
    "plt.legend()\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"Log base 10 z-value\", fontsize = 15)\n",
    "plt.ylabel(\"Count (log base 10 scale)\", fontsize = 15)\n",
    "#plt.savefig(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcdb1a7-000a-451a-96e9-b37075168ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "phis = np.concatenate([np.nonzero(x)[0] for x in decoded_imgs[0]])\n",
    "etas = np.concatenate([np.nonzero(x)[1] for x in decoded_imgs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b065e6-2f37-4c97-90a0-931cd86ebc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "num = 50\n",
    "colors = ['b', 'r', 'g', 'c','m', 'y']\n",
    "plt.hist(etas[.], bins = num, color = colors[3], histtype = 'step', label = 'rapp_org')\n",
    "plt.hist(phis[.], bins = num, color = colors[4], histtype = 'step', label = 'phip_org')\n",
    "plt.hist(rapidity, bins = num, color = colors[1], histtype = 'step', label = 'rap_org')\n",
    "plt.hist(phi, bins = num, color = colors[0], histtype = 'step', label = 'phi_org')\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"Values\", fontsize = 15)\n",
    "plt.ylabel(\"Count (log base 10 scale)\", fontsize = 15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
